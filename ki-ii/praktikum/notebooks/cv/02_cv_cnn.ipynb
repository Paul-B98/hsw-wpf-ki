{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wahlpflichtfach Künstliche Intelligenz II: Praktikum \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Computer Vision: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Im Folgenden sollen Sie ein CNN in TensorFlow bauen. Als Datensatz verwenden wir dafür die [CIFAR-Bilder](https://www.cs.toronto.edu/~kriz/cifar.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets.cifar10 import load_data\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = [\n",
    "    \"airplane\", \n",
    "    \"automobile\", \n",
    "    \"bird\", \n",
    "    \"cat\", \n",
    "    \"deer\",\n",
    "    \"dog\", \n",
    "    \"frog\", \n",
    "    \"horse\", \n",
    "    \"ship\", \n",
    "    \"truck\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 5, figsize=(10,10))\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        axes[i, j].imshow(train_images[i*5+j], cmap=plt.cm.binary)\n",
    "        axes[i, j].set_title(class_names[train_labels[i*5+j][0]])\n",
    "        axes[i, j].axis('off')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Es gibt {len(train_images)} Trainings-Bilder, die eine Größe von {train_images[0].shape} haben.\")\n",
    "print(f\"Es gibt {len(test_images)} Test-Bilder.\")\n",
    "print(f\"Die Labels sind: {set(test_labels.flatten())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.squeeze(tf.one_hot(train_labels, 10))\n",
    "test_labels = tf.squeeze(tf.one_hot(test_labels, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das erste CNN erstellen\n",
    "\n",
    "Bevor wir ein CNN erstellen, sollten sie sich anschauen was ein [Convolutional Layer](https://developers.google.com/machine-learning/glossary?hl=de#convolutional_layer) und ein [Pooling Layer](https://developers.google.com/machine-learning/glossary?hl=de#pooling) sind und wie diese funktionieren.\n",
    "\n",
    "Im Folgenden erstellen wir unser erstes CNN schauen sie sich in ruhe dazu die [Dokumentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers) der Layer die benötigt werden an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "cnn_1 = Sequential(name='cnn_1')\n",
    "# Feature extractor\n",
    "\n",
    "cnn_1.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "cnn_1.add(MaxPooling2D((2, 2)))\n",
    "cnn_1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "cnn_1.add(MaxPooling2D((2, 2)))\n",
    "cnn_1.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "# Classifier\n",
    "cnn_1.add(Flatten())\n",
    "cnn_1.add(Dense(64, activation='relu'))\n",
    "cnn_1.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training des CNNs\n",
    "\n",
    "Das CNN können sie genauso wie alle anderen Modelle in Tensorflow mit `compile()` Kompilieren und mit `fit()` trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "log_dir = \"../../logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "cnn_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_1.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    batch_size=64, \n",
    "    epochs=10, \n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance überprüfen\n",
    "Validieren des Models mit `evaluate()` ist ebenfalls möglich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_1.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(f\"Die Test-Accuracy beträgt {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_1.predict(np.expand_dims(test_images[0], axis=0))\n",
    "\n",
    "y_pred = np.argmax(predictions, axis=1)[0]\n",
    "y_true = np.argmax(test_labels[0])\n",
    "print(f\"predicted label: {class_names[y_pred]} ({y_pred})\")\n",
    "print(f\"actual label: {class_names[y_true]} ({y_true})\")\n",
    "\n",
    "plt.imshow(train_images[0], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Möglichkeiten zur Verbesserung\n",
    "\n",
    "Auch hier können die Hyperparameter optimiert werden, um eine Besser Performance zu erzeugen:\n",
    "- Mehr oder weniger Schichten im Feature Extractor\n",
    "- Andere Kernel Size, Stride Size oder Pooling Size\n",
    "- Mehr oder weniger Kernel in den Convolutional-Schichten\n",
    "\n",
    "Im Folgenden sehen sie ein anderes Beispiel. Optimierung lassen sich ebenfalls mit den vorgestellten suchverfahren mit dem Keras-Tuner erledigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D   \n",
    "\n",
    "cnn_2 = Sequential(name='CNN_2')\n",
    "# Feature extractor\n",
    "cnn_2.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
    "cnn_2.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "cnn_2.add(AveragePooling2D((2, 2)))\n",
    "cnn_2.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "cnn_2.add(Conv2D(128, (7, 7), activation='relu', padding='same'))\n",
    "# Classifier\n",
    "cnn_2.add(GlobalAveragePooling2D())\n",
    "cnn_2.add(Dense(256, activation='relu'))\n",
    "cnn_2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../../logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "cnn_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss=CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "cnn_2.fit(\n",
    "    train_images, \n",
    "    train_labels, \n",
    "    batch_size=64, \n",
    "    epochs=10, \n",
    "    validation_data=(test_images, test_labels),\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_2.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Die Test-Accuracy beträgt {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weiterführende Themen\n",
    "\n",
    "In der Einheit wurden die Grundlagen von CNNs beleuchtet. Zu dieses Thema gibt jedoch noch viele weitere Themen. Die Bibliothek Keras hat mit [KerasCV](https://keras.io/keras_cv/) ein eigenes Segment in den Lösungen für die Datenaufbereitung oder [vortrainierte Modelle](https://keras.io/api/keras_cv/models/) bereitgestellt werden.\n",
    "\n",
    "Zusätzlich gibt es auch mit dem [Transformer](https://huggingface.co/docs/transformers/model_doc/vit) Ansatz CV Lösungen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Wahlpflichtach Künstliche Intelligenz II: Praktikum "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
