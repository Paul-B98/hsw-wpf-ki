{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wahlpflichtach Künstliche Intelligenz I: Praktikum \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Erstes Data Wrangling mit Pandas\n",
    "\n",
    "- [Das Pandas series-Objekt](#Das-Pandas-series-Objekt)\n",
    "- [Das Pandas DataFrame-Objekt](#Das-Pandas-DataFrame-Objekt)\n",
    "- [Das Pandas Index-Objekt](#Das-Pandas-Index-Objekt)\n",
    "- [Indizierung, Auswahl und Zuweisung von Daten](#Indizierung,-Auswahl-und-Zuweisung-von-Daten)\n",
    "- [Lesen von Serien und DataFrames](#Lesen-von-Serien-und-DataFrames)\n",
    "- [Ufuncs und Aggregation](#Ufuncs-und-Aggregation)\n",
    "- [Group-By](#Group-By)\n",
    "- [Aggregate,-filter,-transform,-apply](#Aggregate,-filter,-transform,-apply)\n",
    "- [Plots speichern](#Plots-speichern)\n",
    "\n",
    "Pandas ist eine Bibliothek für schnelle und effiziente Berechnungen auf großen Datenmengen. Wie in Numpy sind auch in Pandas viele Operationen vektorisiert und damit effizient und schnell.\n",
    "\n",
    "\n",
    "Pandas ist ein neueres Paket, das auf NumPy aufbaut und eine effiziente Implementierung eines DataFrames bietet. DataFrames sind im Wesentlichen mehrdimensionale Arrays mit angehängten Zeilen- und Spaltenbezeichnungen und oft mit heterogenen Typen und/oder fehlenden Daten. Pandas bietet nicht nur eine bequeme Speicherschnittstelle für beschriftete Daten, sondern implementiert auch eine Reihe leistungsfähiger Datenoperationen, die Benutzern sowohl von Datenbank-Frameworks (-> relationale Algebra) als auch von Tabellenkalkulationsprogrammen vertraut sind.\n",
    "\n",
    "Wie wir gesehen haben, bietet die ndarray-Datenstruktur von NumPy wesentliche Eigenschaften für die Art von sauberen, gut organisierten Daten, die typischerweise bei numerischen Berechnungsaufgaben vorkommen. Während sie diesen Zweck sehr gut erfüllt, werden ihre Grenzen deutlich, wenn wir mehr Flexibilität benötigen (z. B. das Anhängen von Beschriftungen an Daten, die Arbeit mit fehlenden Daten usw.) und wenn wir Operationen versuchen, die sich nicht gut auf die elementweise Übertragung abbilden lassen (z. B. Gruppierungen, Pivots usw.), was jeweils ein wichtiger Bestandteil der Analyse der weniger strukturierten Daten ist, die in vielen Formen in der Welt um uns herum vorhanden sind. Pandas und insbesondere seine Series- und DataFrame-Objekte bauen auf der NumPy-Array-Struktur auf und bieten einen effizienten Zugriff auf diese Art von \"Datenverarbeitungs\"-Aufgaben, die einen Großteil der Zeit eines Datenwissenschaftlers in Anspruch nehmen.\n",
    "\n",
    "So wie wir numpy normalerweise als np importieren, importieren wir pandas unter dem Alias von pd. Wir importieren auch numpy, weil wir es bei der Verwendung von pandas oft brauchen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Pandas `series`-Objekt\n",
    "\n",
    "Eine Pandas-`series` ist ein eindimensionales Array mit indizierten Daten. Es kann wie folgt aus einer Liste oder einem Array erzeugt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series with missing values \n",
    "data = pd.Series([0.25, 0.5, np.NaN, 1.0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values, type(data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Index ist ein Array-ähnliches Objekt vom Typ `pd.Index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index, type(data.index), list(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bei einer Liste oder einem NumPy-Array kann auf die Daten über den zugehörigen Index über die bekannte Python-Schreibweise mit eckigen Klammern zugegriffen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serie als verallgemeinertes NumPy-Array\n",
    "\n",
    "Nach dem, was wir bisher gesehen haben, mag es so aussehen, als sei das Series-Objekt grundsätzlich austauschbar mit einem eindimensionalen NumPy-Array. Der wesentliche Unterschied ist das Vorhandensein des Indexes: Während das Numpy-Array einen implizit definierten Integer-Index hat, der für den Zugriff auf die Werte verwendet wird, hat die Pandas-Serie einen explizit definierten Index, der mit den Werten verknüpft ist.\n",
    "\n",
    "Diese explizite Indexdefinition verleiht dem Series-Objekt zusätzliche Fähigkeiten. Zum Beispiel muss der Index kein Integer sein, sondern kann aus Werten jedes beliebigen Typs bestehen. Wenn wir wollen, können wir zum Beispiel Zeichenketten als Index verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'd', 'c'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = list(\"AbCD\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"b\"] == data[1] == data.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=[3, 7, 2, 4])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn ein expliziter Index vorhanden ist, wird er bevorzugt! (*Solange wir nicht slicen!*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass explizite Indizes nicht eindeutig sein müssen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.concat([data, data])\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2[7] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serie als spezialisiertes Dictionary\n",
    "\n",
    "Auf diese Weise können Sie sich eine Pandas-Serie ein bisschen wie eine Spezialisierung eines Python-Dictionarys vorstellen. Ein Dictionary ist eine Struktur, die beliebige Schlüssel auf eine Menge von beliebigen Werten abbildet, und eine Series ist eine Struktur, die typisierte Schlüssel auf eine Menge von typisierten Werten abbildet. Diese Typisierung ist wichtig: So wie der typspezifische kompilierte Code hinter einem NumPy-Array es für bestimmte Operationen effizienter macht als eine Python-Liste, macht die Typinformation einer Pandas-Serie sie für bestimmte Operationen viel effizienter als Python-Dictionary.\n",
    "\n",
    "Die Serie-als-Dictionary-Analogie kann noch deutlicher gemacht werden, indem ein Serie-Objekt direkt aus einem Python-Dictionary konstruiert wird:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dict = {'California': 38332521,\n",
    "                   'Texas': 26448193,\n",
    "                   'New York': 19651127,\n",
    "                   'Florida': 19552860,\n",
    "                   'Illinois': 12882135}\n",
    "population = pd.Series(population_dict)\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['Texas']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zu einem Dictionary unterstützt die Serie jedoch auch Array-ähnliche Operationen wie z. B. Slicing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population['California':'Illinois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass Illinois inklusive ist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen von Serienobjekten\n",
    "\n",
    "Daten können ein Skalar sein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(5, index=[100, 200, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten können ein Dictionary sein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser = pd.Series({2:'a', 1:'b', 3:'c'})\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(ser.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Pandas DataFrame-Objekt\n",
    "\n",
    "Die nächste grundlegende Struktur in Pandas ist der DataFrame. Wie das Series-Objekt kann es entweder als eine Verallgemeinerung eines NumPy-Arrays oder als eine Spezialisierung eines Python-Dictionarys betrachtet werden. Wir werden nun einen Blick auf jede dieser Perspektiven werfen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame als verallgemeinertes NumPy-Array\n",
    "\n",
    "Wenn eine Serie ein Analogon zu einem eindimensionalen Array mit flexiblen Indizes ist, ist ein DataFrame ein Analogon zu einem zweidimensionalen Array mit flexiblen Zeilenindizes und flexiblen Spaltennamen. Genauso wie Sie sich ein zweidimensionales Array als eine geordnete Folge von ausgerichteten eindimensionalen Spalten vorstellen können, können Sie sich einen DataFrame als eine Folge von ausgerichteten Series-Objekten vorstellen. Mit \"ausgerichtet\" meinen wir hier, dass sie denselben Index haben.\n",
    "\n",
    "\n",
    "\n",
    "Um dies zu demonstrieren, konstruieren wir zunächst eine neue Serie, die die Fläche jedes der fünf im vorherigen Abschnitt besprochenen Zustände auflistet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,\n",
    "             'Florida': 170312, 'Illinois': 149995}\n",
    "area = pd.Series(area_dict)\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun, da wir dies zusammen mit der Bevölkerungsreihe von vorher haben, können wir ein Dictionary verwenden, um ein einzelnes zweidimensionales Objekt zu konstruieren, das diese Informationen enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = pd.DataFrame({'population': population,\n",
    "                       'area': area,\n",
    "                       'country': 'USA'})\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(states.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sieht aus wie ein verallgemeinertes Dictionary! Die Keys sind die Namen der Staaten, und die Werte sind wie eine Liste `[area, country, population]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.sort_values(by=\"population\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states['population'], type(states['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ermittelt die \"Keys\" (Indizes) des DataFrames, in dem \"Bevölkerung\" seinen Maximalwert hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[\"population\"].idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibt die Serie am angegebenen Index zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc[states[\"population\"].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gibt das Maximum für jede einzelne Spalte zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states['California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.loc['California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(states.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man kann sich den DataFrame als eine Verallgemeinerung eines zweidimensionalen NumPy-Arrays vorstellen, bei dem sowohl die Zeilen als auch die Spalten einen verallgemeinerten Index für den Zugriff auf die Daten haben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame als spezialisiertes Dictionary\n",
    "\n",
    "In ähnlicher Weise können wir uns einen DataFrame auch als eine Spezialisierung eines Dictionarys vorstellen. Wo ein Dictionary einen Key auf einen Value abbildet, bildet ein DataFrame einen Spaltennamen auf eine Serie von Spaltendaten ab. Wenn Sie z. B. nach dem Attribut \"area\" fragen, erhalten Sie das Objekt \"Series\", das die Bereiche enthält, die wir zuvor gesehen haben.\n",
    "\n",
    "Beachten Sie, dass die Indizierung eines DataFrames mit eckigen Klammern die *Spalte* erhält!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(states[\"area\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Erstellen von DataFrame-Objekten\n",
    "\n",
    "Ein Pandas DataFrame kann auf verschiedene Arten konstruiert werden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aus einem einzelnen Series-Objekt\n",
    "\n",
    "Ein DataFrame ist eine Sammlung von Series-Objekten, und ein einspaltiger DataFrame kann aus einer einzigen Series konstruiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(population, columns=['population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aus mehreren Series-Objekten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series(['100', '200', 'python', '300.12', '400'])\n",
    "s2 = pd.Series(['10', '20', 'php', '30.12', '40'])\n",
    "df = pd.concat([s1, s2], axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass viele Funktionen in Pandas das Argument `Achse` nehmen - in diesem Fall können Sie zwischen 0/`Index` und 1/`Spalten` wählen. Wenn Sie explizit sein wollen, empfehle ich die Verwendung der String-Version!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aus einer Liste von Dictionaries \n",
    "\n",
    "Eine beliebige Liste von Dictionaries kann zu einem DataFrame gemacht werden. Wir werden eine einfache List Comprehension verwenden, um einige Daten zu erzeugen. Auch wenn einige Keys im Dictionary fehlen, wird Pandas diese mit NaN (d.h. \"not a number\") Werten auffüllen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}], index=[\"first_dict\", \"second_dict\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da jede einzelne Spalte einen konsistenten D-Typ haben muss und np.NaN ein Float ist, werden einige der Zahlen in Floats umgewandelt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir die Zeilen erhalten wollten, müsste Pandas die Zahlen explizit erzwingen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['first_dict']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aus einem zweidimensionalen NumPy-Array\n",
    "\n",
    "Aus einem zweidimensionalen Array von Daten können wir einen DataFrame mit den angegebenen Spalten- und Indexnamen erstellen. Wenn nichts angegeben wird, wird ein ganzzahliger Index für jede Spalte verwendet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wiederholen Sie das bis jetzt Gelernte in Bezug auf die grundlegenden Objektypen von Pandas für sich!**\n",
    "\n",
    "Bearbeiten Sie inbesondere die folgende **Übung** und schreiben Sie die Antwort am Ende der Bearbeitungszeit in den Chat: \n",
    "\n",
    "**Erzeugen Sie einen DataFrame aus dem angegebenen Dictionary sowie der `qualifies`-Liste, mit den angegebenen Indizes:**\n",
    "```python\n",
    "exam_data = {\n",
    "    'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "    'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "    'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    }\n",
    "\n",
    "qualifies = ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Das Pandas Index-Objekt\n",
    "\n",
    "Wir haben hier gesehen, dass sowohl das Series- als auch das DataFrame-Objekt einen expliziten Index enthalten, mit dem Sie Daten referenzieren und verändern können. Dieses Index-Objekt ist eine interessante Struktur für sich, die man sich als unveränderliches Array vorstellen kann:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = pd.Index([2, 3, 5, 7, 11])\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = pd.Series(0, index=ind)\n",
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index-Objekte haben einen Namen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.names = ['indexx']\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = pd.Series(np.zeros_like(ind), index=ind)\n",
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.zeros_like(ind), index=ind, columns=['first'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.names = [None]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index-Objekte haben auch viele der Attribute, die von NumPy-Arrays bekannt sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind.size, ind.shape, ind.ndim, ind.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während die Betrachtung von Indizes als unveränderliche Liste natürlich ist, erlauben Indizes auch Mengenoperationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA = pd.Index([1, 3, 5, 7, 9])\n",
    "indB = pd.Index([2, 3, 5, 7, 11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA & indB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA | indB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indA ^ indB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indizierung, Auswahl und Zuweisung von Daten\n",
    "\n",
    "Aus dem Numpy Notebook kennen wir bereits Indizierung, Slicing, Maskierung und Fancy Indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16).reshape(4,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nimmt die Werte der zweiten und vierten Spalte, die durch 3 teilbar sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:, [1, 3]][a[:, [1, 3]] % 3 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier werden wir uns ähnliche Möglichkeiten des Zugriffs auf und der Änderung von Werten in Pandas Series- und DataFrame-Objekten ansehen. Die entsprechenden Muster in Pandas sind denen von Numpy sehr ähnlich, obwohl es ein paar Besonderheiten zu beachten gibt.\n",
    "\n",
    "Wir beginnen mit dem einfachen Fall des eindimensionalen Series-Objekts und gehen dann zu dem etwas komplizierteren zweidimensionalen DataFrame-Objekt über."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenauswahl in Serien\n",
    "\n",
    "Wie wir im vorherigen Abschnitt gesehen haben, verhält sich ein Series-Objekt in vielerlei Hinsicht wie ein eindimensionales NumPy-Array und in vielerlei Hinsicht wie ein Standard-Python-Dictionary. Wenn wir uns diese beiden sich überschneidenden Analogien vor Augen halten, wird es uns helfen, die Muster der Datenindizierung und -auswahl in diesen Arrays zu verstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serie als Dictionary\n",
    "\n",
    "Wie ein Dictionary bietet das Series-Objekt eine Abbildung von einer Sammlung von Keys auf eine Sammlung von Values, was bedeutet, dass die meisten der entsprechenden Funktionen genauso gut für sie funktionieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=['a', 'b', 'c', 'd'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.__contains__('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'b' in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(data.keys(), data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['e'] = 1.25\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Serie als eindimensionales Array\n",
    "\n",
    "Series baut auf dieser wörterbuchähnlichen Schnittstelle auf und bietet die Auswahl von Elementen im Array-Stil über die gleichen grundlegenden Mechanismen wie NumPy-Arrays - also Slices, Maskierung und ausgefallene Indexierung. Beispiele hierfür sind die folgenden:\n",
    "\n",
    "* Slicing durch expliziten Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['a':'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Slicing durch impliziten Integer-Index\n",
    "\n",
    "(Beachten Sie, dass beim Slicing mit einem expliziten Index (d. h. data['a':'c']) der letzte Index in das Slice eingeschlossen wird, während beim Slicing mit einem impliziten Index (d. h. data[0:2]) der letzte Index vom Slice ausgeschlossen wird.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data > 0.3) & (data < 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Maskierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data > 0.3) & (data < 0.8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['a', 'e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.25, 0.5, 0.75, 1.0],\n",
    "                 index=[1, 2, 3, 4])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wenn Ihre Serie einen expliziten Integer-Index hat, verwendet eine Indizierungsoperation wie `data[1]` die expliziten Indizes, während eine Slicing-Operation wie `data[1:3]` den impliziten Index im Python-Stil verwendet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 5, 3])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliziter Index bei Indizierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impliziter Index beim Slicen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das `loc`-Attribut ermöglicht eine Indizierung und Slicing, die *immer* auf den expliziten Index verweist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass `loc` beim Slicen Index-Fehler auslösen kann, aber nicht muss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 5, 3])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['a':'z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[3:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series(['a', 'b', 'c'], index=[1, 3, 5])\n",
    "data.loc[3:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc['a':'z']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Attribut `iloc` ermöglicht eine Indizierung und Slicing, die immer auf den impliziten Index im Python-Stil verweist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bitte, ersparen Sie sich den Schmerz und seien Sie immer explizit über das, was Sie tun -- benutzen Sie immer ``.loc`` und ``.iloc``\n",
    "\n",
    "**Explicit is better than implicit.**\n",
    "\n",
    "Die Aussage ist **nicht**, dass explizite Indizes besser sind als implizite, sondern dass Sie explizit sein sollten, was Sie tun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nachtrag: Indizierung\n",
    "\n",
    "Aus [der Doku][1]: In früheren Versionen funktionierte die Verwendung von .loc[list-of-labels], solange mindestens 1 der Schlüssel gefunden wurde (andernfalls wurde ein KeyError ausgelöst). Dieses Verhalten ist jetzt veraltet!\n",
    "\n",
    "[1]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc[[1, 2, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stattdessen sollten Sie sich für [`reindex`][1] entscheiden, das die Serie/DF an einen neuen Index mit optionaler Fülllogik anpasst.\n",
    "\n",
    "[1]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reindex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.reindex([1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenselektion in DataFrames\n",
    "\n",
    "Erinnern Sie sich daran, dass sich ein DataFrame in vielerlei Hinsicht wie ein zweidimensionales oder strukturiertes Array verhält und in anderer Hinsicht wie ein Wörterbuch mit Reihenstrukturen, die denselben Index haben. Diese Analogien können hilfreich sein, wenn wir die Datenauswahl innerhalb dieser Struktur untersuchen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'California': 423967, 'Texas': 695662,\n",
    "                  'New York': 141297, 'Florida': 170312,\n",
    "                  'Illinois': 149995})\n",
    "pop = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                 'New York': 19651127, 'Florida': 19552860,\n",
    "                 'Illinois': 12882135})\n",
    "data = pd.DataFrame({'area':area, 'pop':pop, 'Country':'USA'})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass wir, wenn wir einen DataFrame indizieren, die **Spalte** indizieren!!! Die Indizierung im Stil eines Dictionarys ergibt eine Serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(data[\"area\"]))\n",
    "data[\"area\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können auch dereferenzieren, allerdings führt das zu Seiteneffekten, auch wenn das eigentlich auch eine Methode ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit diesem Bild im Kopf können viele bekannte Array-ähnliche Beobachtungen am DataFrame selbst durchgeführt werden. Zum Beispiel können wir den gesamten DataFrame transponieren, um Zeilen und Spalten zu vertauschen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Indexierung im Array-Stil verwendet Pandas wieder die bereits erwähnten loc- und iloc-Indexer. Mit dem iloc-Indexer können wir das zugrundeliegende Array so indizieren, als wäre es ein einfaches NumPy-Array (unter Verwendung des impliziten Python-Style-Index), **aber der DataFrame-Index und die Spaltenbeschriftungen werden im Ergebnis** beibehalten (Indizierung des zugrunde liegenden Numpy-Arrays):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.values[:3, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:3, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:'Illinois', :'pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:,['area','pop']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So bekommen wir eine Reihe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[\"California\", :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinzufügen einer neuen Spalte (mit Vektor-Berechnungen):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['density'] = data['pop'] / data['area']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können eine Maskierung mit Fancy Indexing kombinieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data.density > 100, ['pop', 'density']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie explizite und implizite Indizierung kombinieren wollen, müssen Sie sie verketten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:4].loc[:, ['pop', 'density']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Während sich die Indizierung auf Spalten bezieht, bezieht sich Slicing auf Zeilen:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Florida':'Illinois']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier gilt: Seien Sie bei der Indizierung lieber explizit, um sich eine Menge Verwirrung zu ersparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area':'pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'area':'pop']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schneller Zugriff auf einen einzelnen Teilnehmer mit **at**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "data.loc['Florida', 'pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "data.at['Florida', 'pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = ['Firefox', 'Chrome', 'Safari', 'IE10', 'Konqueror']\n",
    "df = pd.DataFrame({'http_status': [200, 200, 404, 404, 301],\n",
    "                  'response_time': [0.04, 0.02, 0.07, 0.08, 1.0]},\n",
    "                  index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = ['Safari', 'Iceweasel', 'Comodo Dragon', 'IE10', 'Chrome']\n",
    "df.reindex(new_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reindex(columns=['http_status', 'user_agent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Renaming indices** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"a\": [1, 2, 3, 4], \"b\": [2, 5, 7, 8]})\n",
    "df = df.rename(mapper={'b': 'c'}, axis='columns')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101', periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list('ABCD'))\n",
    "df['E'] = [\"one\", \"two\", \"three\"] * 2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['A'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('A > 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Alternative Syntax](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) für `query`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['E'].isin(['one','two'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['E'].isin(['one','two'])] = np.NaN\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isna(df).any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machen Sie sich jetzt vertieft mit der Indizierung, der Auswahl und der Zuweisung von Daten in Pandas vertraut!**\n",
    "\n",
    "Bearbeiten Sie inbesondere die folgende **Übung** und schreiben Sie die Antwort am Ende der Bearbeitungszeit in den Chat: \n",
    "\n",
    "**Schreiben Sie ein Pandas-Snippet, um die Namen und Punktzahlen der Personen, bei denen die Anzahl der Versuche in der Prüfung größer als 2 ist, als Dictionary zu erhalten.**\n",
    "```python\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael',\n",
    "                      'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "    'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "    'attempts' : [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "    'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "df\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datenzuweisung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
    "                  index=['Portland', 'Berkeley'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spalten zuweisen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country'] = 'USA'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_c'] <= 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['too_cold'] = df['temp_c'] <= 18\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese arbeiten jedoch in-place. Um die Werte einem neuen Datenframe zuzuweisen, verwenden Sie `assign`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'temp_c': [17.0, 25.0]},\n",
    "                  index=['Portland', 'Berkeley'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized version:\n",
    "df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n",
    "          temp_k=lambda x: (x['temp_f'] +  459.67) * 5 / 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehrere Zuordnungen gleichzeitig sind ebenfalls möglich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeilenzuordnungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Berkeley', 'temp_c'] = 26.0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['Portland'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Portland'] = pd.Series({'temp_c': 99})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Osnabruck', 'temp_c'] = 18\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Osnabruck', 'temp_c'] = 25\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Osnabruck'] = pd.Series({'temp_c': 99})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.loc['Osnabruck'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df.index == 'Osnabruck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[np.where(df.index == 'Osnabruck')[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[np.where(df.index == 'Osnabruck')[0][0]] = pd.Series({'temp_c': 99})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Indizierung\n",
    "\n",
    "Obwohl Pandas Objekte zur Verfügung stellt, die nativ mit drei- und vierdimensionalen Daten umgehen können, ist es in der Praxis weitaus verbreiteter, eine \"hierarchische Indizierung\" (auch bekannt als \"Multi-Indizierung\") zu verwenden, um mehrere Indexebenen innerhalb eines einzigen Indexes einzubinden. Auf diese Weise können höherdimensionale Daten kompakt innerhalb der bekannten eindimensionalen Series- und zweidimensionalen DataFrame-Objekte dargestellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "pop = pd.Series(populations, index=index)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.MultiIndex.from_tuples(index)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.names = ['state', 'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = pop.reindex(index)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop['California', 2000], pop['California', 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Indizierung\n",
    "\n",
    "Obwohl Pandas Objekte zur Verfügung stellt, die nativ mit drei- und vierdimensionalen Daten umgehen können, ist es in der Praxis weitaus verbreiteter, eine \"hierarchische Indizierung\" (auch bekannt als \"Multi-Indizierung\") zu verwenden, um mehrere Indexebenen innerhalb eines einzigen Indexes einzubinden. Auf diese Weise können höherdimensionale Daten kompakt innerhalb der bekannten eindimensionalen Series- und zweidimensionalen DataFrame-Objekte dargestellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.names = [None, None]\n",
    "pop = pop.reindex(index)\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.index.names = [None, None]\n",
    "pop.unstack().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdf = pop.unstack(level=0)\n",
    "popdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdf.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index setzen und zurücksetzen\n",
    "\n",
    "Eine weitere Möglichkeit, hierarchische Daten neu zu ordnen, besteht darin, die Indexbezeichnungen in Spalten umzuwandeln; dies kann mit der Methode ``reset_index`` erreicht werden.\n",
    "\n",
    "Der Aufruf dieser Methode auf dem Populationsverzeichnis führt zu einem ``DataFrame`` mit einer *Staat* und *Jahr* Spalte, die die Informationen enthält, die vorher im Index waren.\n",
    "\n",
    "Der Übersichtlichkeit halber können wir optional den Namen der Daten für die Spaltendarstellung angeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.index.names = ['state', 'year']\n",
    "print(type(pop))\n",
    "pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_flat = pop.reset_index(name='population')\n",
    "pop_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man in der realen Welt mit Daten arbeitet, sehen die rohen Eingabedaten oft so aus und es ist nützlich, einen ``MultiIndex`` aus den Spaltenwerten zu bilden.\n",
    "\n",
    "Das kann man mit der Methode ``set_index`` des ``DataFrame`` machen, die einen mehrfach indizierten ``DataFrame`` zurückgibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pop_flat.set_index(['state', 'year'])\n",
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df.rename_axis([None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = pop_df.rename_axis([None, None]).unstack()\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf[\"area\"] = 999\n",
    "asdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(asdf[\"area\"]))\n",
    "asdf[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(asdf[\"population\"]))\n",
    "asdf[\"population\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df2 = pop_flat.set_index('state').rename_axis(None)\n",
    "pop_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesen von Serien und DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/06/Pokemon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stellen Sie sich vor, jemand gibt Ihnen einen zufälligen Datensatz. Sie kennen nichts von dessen Inhalt. Was sind die ersten Schritte, die Sie tun?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Type 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Legendary\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie mit csvs arbeiten, sollten Sie unbedingt darauf achten, ob Sie die erste Spalte als Index-Spalte haben wollen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/06/Pokemon.csv\", index_col=0)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index().drop_duplicates(subset=\"#\").tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Name'] != 'Volcanion']\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates = df.reset_index().drop_duplicates(subset=\"#\").reset_index().drop(\"index\", axis=1)  \n",
    "no_duplicates.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_duplicates.set_index(\"#\").to_csv('data/06/Pokemon_no_duplicates.csv')\n",
    "#no_duplicates.to_excel('Pokemon_no_duplicates.xlsx', sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_one = no_duplicates[no_duplicates[\"Generation\"] == 1].set_index(\"#\")\n",
    "gen_one.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_gen_dict = gen_one[\"Name\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(key)+\" : \"+str(val) for index, (key, val) in enumerate(first_gen_dict.items()) if index < 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dokumentation!**\n",
    "\n",
    "Es gibt wirklich sehr viele Argumente für diese Funktion, passend für alle Ihre Bedürfnisse!\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ufuncs und Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation in Pandas\n",
    "\n",
    "Aggregationen sind Funktionen, bei denen eine oder mehrere Dimensionen von Daten auf einen einzigen Wert zusammengefasst werden, wie z.B. die `max`, `sum` oder `mean`- Funktionen.\n",
    "\n",
    "Stat-Operationen *exkludieren* im Allgemeinen fehlende Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Für Serien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(7)\n",
    "ser = pd.Series(a**2, index=a)\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Für DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': a**2,\n",
    "                   'B': a**3})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die folgende Tabelle fasst einige weitere eingebaute Pandas-Aggregationen zusammen:\n",
    "\n",
    "| Aggregation | Beschreibung |\n",
    "|--------------------------|---------------------------------|\n",
    "| ``count()`` | Gesamtzahl der Elemente |\n",
    "| ``first()``, ``last()`` | Erstes und letztes Element |\n",
    "| ``mean()``, ``median()`` | Mittelwert und Median |\n",
    "| ``min()``, ``max()`` | Minimum und Maximum |\n",
    "| ``std()``, ``var()`` | Standardabweichung und Varianz |\n",
    "| ``mad()`` | Mittlere absolute Abweichung |\n",
    "| ``prod()`` | Produkt aller Positionen |\n",
    "| ``sum()`` | Summe aller Elemente |\n",
    "\n",
    "Dies sind alles Methoden der Objekte ``DataFrame`` und ``Series``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ufuncs\n",
    "\n",
    "Ufuncs kennen wir bereits aus Numpy: Das sind vektorisierte Funktionen, die alle Werte eines Arrays gleichzeitig verändern. \n",
    "\n",
    "Pandas macht dasselbe, mit einem netten Twist: Für unäre Operationen wie Negation und trigonometrische Funktionen werden diese Ufuncs die Index- und Spaltenbeschriftungen in der Ausgabe *beibehalten*, und für binäre Operationen wie Addition und Multiplikation wird Pandas die Indizes automatisch *ausrichten*, wenn die Objekte an die Ufunc übergeben werden.\n",
    "\n",
    "Das bedeutet, dass das Beibehalten des Kontexts von Daten und das Kombinieren von Daten aus verschiedenen Quellen - beides potenziell fehleranfällige Aufgaben mit rohen NumPy-Arrays - mit Pandas im Wesentlichen narrensicher werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "df = pd.DataFrame(rng.randint(0, 10, (3, 4)),\n",
    "                  columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ufuncs: Index-Ausrichtung\n",
    "\n",
    "Bei binären Operationen auf zwei ``Series``- oder ``DataFrame``-Objekten richtet Pandas die Indizes während der Ausführung der Operation aus.\n",
    "\n",
    "Dies ist sehr praktisch, wenn man mit unvollständigen Daten arbeitet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.Series({'Alaska': 1723337, 'Texas': 695662,\n",
    "                  'California': 423967}, name='area')\n",
    "population = pd.Series({'California': 38332521, 'Texas': 26448193,\n",
    "                        'New York': 19651127}, name='population')\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area & population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area / population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"divide\" in dir(pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdens = area.divide(population, fill_value=0)\n",
    "popdens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popdens = popdens.replace([np.inf, -np.inf], np.nan)\n",
    "popdens.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(rng.randint(0, 20, (2, 2)),\n",
    "                 columns=list('AB'))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.DataFrame(rng.randint(0, 20, (3, 3)),\n",
    "                 columns=list('ABC'))\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.add(B, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Index-Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': np.random.randint(3, size=10)}, index=np.arange(1, 20, 2))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fügen wir eine neue Spalte zu diesem DataFrame hinzu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.Series([0]*len(df.index))\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['new'] = tmp   #changes the original one\n",
    "df.assign(new=tmp) #creates a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index | tmp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_aligned, new_aligned = df.align(tmp, axis=0)\n",
    "old_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_aligned.assign(new=new_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.Series([0]*len(df.index), index=df.index)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['new'] = tmp\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie mehr als eine Operation (ufunc/Aggregation) anwenden wollen, verwenden Sie `agg()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9],\n",
    "                   [np.nan, np.nan, np.nan]],\n",
    "                  columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg(['sum', 'min'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können auch verschiedene Aggregationen für verschiedene Spalten verwenden: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das funktioniert auch für ufuncs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.agg({'A' : 'exp', 'B' : [np.exp, 'sqrt']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply()\n",
    "\n",
    "Während einige ufuncs (wie cumsum oder exp) von Pandas vordefiniert sind, kann die Methode `apply` verwendet werden, um eine beliebige Funktion auf alle Elemente einer Serie oder eines DataFrame anzuwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(7)\n",
    "df = pd.DataFrame({'A': a**2,\n",
    "                   'B': a**3})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(np.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A_cumsum\"] = df.cumsum()[\"A\"]\n",
    "df[\"B_cumsum\"] = df.apply(np.cumsum)[\"B\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Lambda-Funktionen können wir `apply` mit beliebigen Funktionen kombinieren. Beachten Sie, dass das Argument der Funktion immer eine ganze Spalte des Datensatzes ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: print(x, end='\\n\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_more_complex_func(ser):\n",
    "    res = []\n",
    "    for elem in ser:\n",
    "        print(elem if elem > 16 else -elem)\n",
    "        res.append(elem if elem > 16 else -elem)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(my_more_complex_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A\"].apply(lambda x: print(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"A_normed\"] = df[\"A\"].apply(lambda x: x/df[\"A\"].max())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können sogar Dictionaries mit der apply-Funktion verwenden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_moves = {\"Normal\": \"Breakneck Blitz\", \"Fighting\": \"All-Out Pummeling\", \"Flying\": \"Supersonic Skystrike\", \"Poison\": \"Acid Downpour\", \"Ground\": \"Tectonic Rage\", \"Rock\": \"Continental Crush\", \"Bug\": \"Savage Spin-Out\", \"Ghost\": \"Never-Ending Nightmare\",\n",
    "\"Steel\": \"Corkscrew Crash\", \"Fire\": \"Inferno Overdrive\", \"Water\": \"Hydro Vortex\", \"Grass\": \"Bloom Doom\", \"Electric\": \"Gigavolt Havoc\", \"Psychic\": \"Shattered Psyche\", \"Ice\": \"Subzero Slammer\", \"Dragon\": \"Devastating Drake\", \"Dark\": \"Black Hole Eclipse\", \"Fairy\": \"Twinkle Tackle\"}\n",
    "df = pd.read_csv(\"data/06/Pokemon.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Z-Move\"] = df[\"Type 1\"].apply(lambda x:z_moves[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `apply` können wir auch eine Liste von Reihen in einen DataFrame umwandeln, indem wir die einzelnen Spalten zu Reihen machen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([ ['Red', 'Green', 'White'], ['Red', 'Black'], ['Yellow']]) \n",
    "print(type(s))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = s.apply(pd.Series)\n",
    "print(type(df))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notiz zur Geschwindigkeit:**\n",
    "\n",
    "Laut ([1]) ist `apply()` doppelt so schnell wie das Durchlaufen von `iterrows()` einer df und 8 mal so schnell wie das Durchlaufen von Python-Listen.\n",
    "\n",
    "Beachten Sie jedoch, dass `apply()` zwar viel schneller beim Schleifen über die Zeilen Ihres DataFrame/Series ist (indem es eine Reihe von internen Optimierungen nutzt, wie z.B. die Verwendung von Iteratoren in Cython), aber immer noch von Natur aus über Zeilen schleift. Was auch immer Sie anwenden, Sie führen es immer noch einmal für jede Zeile aus. Wo immer Sie also vektorisierte Ufuncs verwenden können, tun Sie das - das ist viel optimierter und parallelisierter - für ([1]) führte der Austausch der Haversinus-Abstandsformel mit ihrem vektorisierten Gegenstück zu einer 50-fachen Zeitersparnis!\n",
    "\n",
    "[1]: https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wiederholen Sie jetzt die verschiedenen Funktionen und die Möglichkeiten der Aggregation in Pandas!**\n",
    "\n",
    "Bearbeiten Sie inbesondere die folgende **Übung** und schreiben Sie die Antwort am Ende der Bearbeitungszeit in den Chat: \n",
    "\n",
    "**Schreiben Sie ein Pandas-Programm, um Reihen von Listen in eine Reihe zu konvertieren.**\n",
    "```python\n",
    "s = pd.Series([ ['Red', 'Green', 'White'], ['Red', 'Black'], ['Yellow']])\n",
    "s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group-By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split-Apply-Combine\n",
    "\n",
    "Während einfache Operationen bereits von Pandas vordefiniert sind, können benutzerdefinierte Aggregationen und Operationen über **group-by** durchgeführt werden. Die Group-by-Operation kann mit den folgenden Schritten beschrieben werden:\n",
    "\n",
    "* **Split:** Aufteilung der Daten in Gruppen basierend auf einigen Kriterien (Aufteilung und Gruppierung in Abhängigkeit vom Wert eines Schlüssels)\n",
    "* **Apply:** Anwendung einer Funktion auf jede Gruppe unabhängig (Aggregation, Transformation, Filterung, ...)\n",
    "* **Combine:** Zusammenfassen der Ergebnisse in einer Datenstruktur\n",
    "\n",
    "Ein typisches Beispiel, bei dem die *Anwendung* eine Summierungsaggregation ist, ist hier dargestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array([list(\"ABCABC\"), np.arange(1,7)]).T\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tmp, columns=[\"key\", \"data\"])\n",
    "df[\"data\"] = pd.to_numeric(df[\"data\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass nicht ein Satz von \"DataFrames\" zurückgegeben wird, sondern ein \"DataFrameGroupBy\"-Objekt. In diesem Objekt liegt die Magie: Sie können es sich als eine spezielle Ansicht der `DataFrames` vorstellen, die bereit ist, in den Gruppen zu graben, aber keine tatsächliche Berechnung durchführt, bis die Aggregation angewendet wird. Dieser \"Lazy-Evaluation\"-Ansatz bedeutet, dass gängige Aggregate sehr effizient und für den Benutzer nahezu transparent implementiert werden können.\n",
    "\n",
    "Um ein Ergebnis zu erzeugen, können wir ein Aggregat auf dieses \"DataFrameGroupBy\"-Objekt anwenden, das die entsprechenden Anwendungs-/Verbindungsschritte durchführt, um das gewünschte Ergebnis zu erzeugen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key\").sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können die Spaltenindizierung genau wie bei einem normalen DataFrame durchführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key\")[\"data\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration über Gruppen\n",
    "\n",
    "Das ``GroupBy``-Objekt unterstützt die direkte Iteration über die Gruppen und gibt jede Gruppe als ``Series`` oder ``DataFrame`` zurück:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key, _) in df.groupby(\"key\"):\n",
    "    print(key)\n",
    "    \n",
    "print()\n",
    "for (_, group) in df.groupby(\"key\"):\n",
    "    print(group, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkm = pd.read_csv('data/06/Pokemon.csv')\n",
    "pkm.groupby('Generation')['Total'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispatch-Methoden\n",
    "\n",
    "Jede Methode, die nicht explizit durch das ``GroupBy``-Objekt implementiert ist, wird durchgereicht und auf den Gruppen aufgerufen, egal ob es sich um ``DataFrame``- oder ``Series``-Objekte handelt.\n",
    "Zum Beispiel können Sie die Methode ``describe()`` von ``DataFrame`` verwenden, um eine Reihe von Aggregationen durchzuführen, die jede Gruppe in den Daten beschreiben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"key\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/06/Pokemon_no_duplicates.csv\", index_col=0)\n",
    "df.groupby('Generation')[\"Name\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wiederholen Sie jetzt die verschiedenen Funktionen und die Möglichkeiten der Aggregation in Pandas!**\n",
    "\n",
    "Bearbeiten Sie inbesondere die folgende **Übung** und schreiben Sie die Antwort am Ende der Bearbeitungszeit in den Chat: \n",
    "\n",
    "**Der gegebene Datensatz enthält eine Spalte `Region` sowie eine Spalte `Pop. Density`. Schreiben Sie ein Snippet, das als Argument den Datenrahmen mit allen Ländern nimmt und eine `Series` zurückgibt, die Regionen auf die durchschnittliche Bevölkerungsdichte ihrer Länder abbildet.**\n",
    "```python\n",
    "countries = pd.read_csv('data/06/countries.csv', index_col=0)\n",
    "countries.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate, filter, transform, apply\n",
    "\n",
    "Bisher haben wir uns auf das Aggregieren für die combine-Operation konzentriert, aber es gibt noch mehr Möglichkeiten.\n",
    "Insbesondere ``GroupBy``-Objekte haben ``aggregate()``, ``filter()``, ``transform()`` und ``apply()``-Methoden, die eine Vielzahl nützlicher Operationen effizient implementieren, bevor die gruppierten Daten kombiniert werden.\n",
    "\n",
    "Für die Zwecke der folgenden Unterabschnitte werden wir diesen ``DataFrame`` verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df():\n",
    "    rng = np.random.RandomState(0)\n",
    "    df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                       'data1': range(6),\n",
    "                       'data2': rng.randint(0, 10, 6)},\n",
    "                       columns = ['key', 'data1', 'data2'])\n",
    "    return df\n",
    "    \n",
    "df = create_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation\n",
    "\n",
    "Während wir bereits einige *Aggregations-Funktionen* verwendet haben, ist die Funktion `aggregate` die explizite Version davon.  \n",
    "Sie kann eine Zeichenkette, eine Funktion oder eine Liste davon nehmen und alle Aggregate auf einmal berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').agg(['min', np.median, max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein weiteres nützliches Vorgehen ist die Übergabe eines Wörterbuchs, das (alte) Spaltennamen auf Operationen abbildet, die auf diese Spalte angewendet werden sollen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate({'data1': 'min',\n",
    "                             'data2': 'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').aggregate({'data1': np.sum,\n",
    "                             'data2': lambda x: np.std(x, ddof=1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benannte Aggregation\n",
    "\n",
    "Um spaltenspezifische Aggregation mit Kontrolle über die *Ausgabespaltennamen* zu unterstützen, akzeptiert Pandas sogenannte benannte Aggregation in `GroupBy.agg()`, wobei:\n",
    "\n",
    "* Die Schlüsselwörter sind die Namen der Ausgabespalten\n",
    "* Die Werte sind Tupel, deren erstes Element die auszuwählende Spalte und das zweite Element die Aggregation ist, die auf diese Spalte angewendet werden soll. \n",
    "    * Alternativ können Sie das NamedAgg-Tupel pandas.NamedAgg mit den Feldern ['column', 'aggfunc'] verwenden, um deutlicher zu machen, was die Argumente sind. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = pd.DataFrame({'kind': ['cat', 'dog', 'cat', 'dog'],\n",
    "                        'height': [9.1, 6.0, 9.5, 34.0],\n",
    "                        'weight': [7.9, 7.5, 9.9, 198.0]})\n",
    "animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert int(pd.__version__[0]) >= 1, 'Your version of pandas is too old for this!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals.groupby(\"kind\").agg(\n",
    "       min_height = pd.NamedAgg(column='height', aggfunc='min'),\n",
    "       max_height = pd.NamedAgg(column='height', aggfunc='max'),\n",
    "       average_weight = pd.NamedAgg(column='weight', aggfunc=np.mean),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtern\n",
    "\n",
    "Mit einer Filterung können Sie Daten basierend auf den Gruppeneigenschaften ausschließen.\n",
    "Zum Beispiel könnten wir alle Gruppen behalten wollen, in denen die Standardabweichung größer als ein kritischer Wert ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x['data2'].std() > 4\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass dies kein Aggregat ist - das Ergebnis hat die Form des ursprünglichen DataFrame, nur dass bestimmte Zeilen weggelassen wurden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').filter(filter_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Methode apply()\n",
    "\n",
    "Mit der Methode ``apply()`` können Sie eine beliebige Funktion auf die Gruppenergebnisse anwenden.\n",
    "Die Funktion sollte einen ``DataFrame`` annehmen und entweder ein Pandas Objekt (z.B. ``DataFrame``, ``Series``) oder einen Skalar zurückgeben; die Kombinationsoperation wird auf den Typ der zurückgegebenen Ausgabe zugeschnitten.\n",
    "\n",
    "Erinnern Sie sich zunächst an unser ``apply()`` von vorhin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df()\n",
    "df[\"data1\"] = df[\"data1\"].apply(lambda x: x/df[\"data1\"].max())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beachten Sie, dass ``groupby`` nur eine *Ansicht des ursprünglichen DataFrame* zurückgibt. Hier ist eine ``Anwendung()``, die die (gruppierte) erste Spalte durch die Summe der (gruppierten) zweiten normalisiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "try:\n",
    "    del newdf\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df()\n",
    "sums = df.groupby('key')[\"data2\"].sum()\n",
    "print(sums, '\\n\\n\\n')\n",
    "for key, group in df.groupby('key'):\n",
    "    group[\"data1\"] /= sums[key]\n",
    "    try:\n",
    "        newdf = newdf.append(group) #appending to dataframes is bad style!\n",
    "    except:\n",
    "        newdf = group.copy()\n",
    "    print(newdf, '\\n')\n",
    "\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_by_data2(x):\n",
    "    # x is a DataFrame of group values\n",
    "    x['data1'] /= x['data2'].sum()\n",
    "    return x\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('key').apply(norm_by_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angeben des Split-Schlüssels\n",
    "\n",
    "In den zuvor vorgestellten einfachen Beispielen haben wir den ``DataFrame`` auf einen einzelnen Spaltennamen aufgeteilt.\n",
    "Dies ist nur eine von vielen Optionen, mit denen die Gruppen definiert werden können, und wir werden hier einige andere Optionen für die Gruppenspezifikation durchgehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eine Liste, ein Array, eine Serie oder ein Index, der die Gruppierungsschlüssel liefert\n",
    "\n",
    "Der Schlüssel kann eine beliebige Serie oder Liste mit einer Länge sein, die der des ``DataFrame`` entspricht. Zum Beispiel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = [0, 1, 0, 1, 2, 0]\n",
    "df.groupby(L).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ein Dictionary oder eine Serie, die den Index auf die Gruppe abbildet\n",
    "\n",
    "Eine andere Methode ist die Bereitstellung eines Dictionarys, das Indexwerte auf die Gruppenschlüssel abbildet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.set_index('key')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}\n",
    "df2.groupby(mapping).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Gruppierung nach mehreren Spalten bildet einen hierarchischen Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby([mapping, \"key\"]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video-Tutorial von Pycon 2015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('5JnMutdy6Fw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist das Übungsblatt zu diesem Notebook: [**06 - Übungsaufgaben Erstes Data Wrangling mit Pandas**](06_uebungsaufgaben_erstes_data_wrangling_mit_pandas.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Wahlpflichtach Künstliche Intelligenz I: Praktikum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "90426636d83e24cdadcd62d77212f0f01714dea61fbf228ca5d2a0125536a635"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
